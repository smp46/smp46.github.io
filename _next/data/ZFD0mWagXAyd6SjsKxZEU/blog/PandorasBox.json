{"pageProps":{"frontMatter":{"title":"Pandora's Box","subtitle":"Developing an LLM-Powered Web Honeypot in 96 Hours","type":"personal","description":"Pandora's Box is an AI powered web honey-pot that utilises a fine-tuned version of distilgpt2. Through the use of an LLM, relevant, specific and personalised responses can be made to every incoming request. The project was built with Python, Golang and Typescript.\nüèÜ 5th Place Winner at LaunchHacks IV Hackathon üèÜ","keywords":"Pandoras Box, CyberSec, Hackathon, Honeypot, LLM, AI, Machine Learning, Golang, Python, Typescript, Next.js","github":"https://github.com/Honeypotters/PandorasBox","featured":true,"heroImage":"https://cdn.statically.io/gh/smp46/smp46.me/nextjs/public/assets/pandorasbox/logo.webp","date":"2025-07-15","created":"2025-07-15","updated":"2025-07-15","readingTime":"4 min read","wordCount":684,"minutes":4},"mdxSource":{"compiledSource":"\"use strict\";\nconst {Fragment: _Fragment, jsx: _jsx, jsxs: _jsxs} = arguments[0];\nconst {useMDXComponents: _provideComponents} = arguments[0];\nfunction _createMdxContent(props) {\n  const _components = {\n    a: \"a\",\n    h1: \"h1\",\n    h2: \"h2\",\n    h3: \"h3\",\n    img: \"img\",\n    p: \"p\",\n    ..._provideComponents(),\n    ...props.components\n  };\n  return _jsxs(_Fragment, {\n    children: [_jsx(_components.p, {\n      children: _jsx(_components.img, {\n        src: \"https://cdn.statically.io/gh/smp46/smp46.me/nextjs/public/assets/pandorasbox/title.webp\",\n        alt: \"Title\"\n      })\n    }), \"\\n\", _jsx(_components.h1, {\n      id: \"pandoras-box-developing-an-llm-powered-web-honeypot-in-96-hours\",\n      children: \"Pandora's Box: Developing an LLM-Powered Web Honeypot in 96 Hours\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"the-problem\",\n      children: \"The Problem\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"The idea of a Honeypot is to detect and collect information on attackers by\\npretending to be an open server. The downside is that Honeypots normally return\\na static, generic or no response, which can tip off attackers and prevent\\ndefenders from gaining valuable insights.\"\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"the-solution\",\n      children: \"The Solution\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"In the age of large language models, why settle for a basic response? Given that\\na web request is all readable text, it is relatively simple to feed it to and\\nget a response from a Large Language Model. So that is what my team and I, the\\naptly named \", _jsx(_components.a, {\n        href: \"https://github.com/Honeypotters/\",\n        children: \"Honeypotters\"\n      }), \", set out to do.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"does-it-already-exist\",\n      children: \"Does it Already Exist?\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"Yes, in a way. Through my research I found an existing solution called\\n\", _jsx(_components.a, {\n        href: \"github.com/0x4D31/galah\",\n        children: \"Galah\"\n      }), \". It largely achieves what we aimed for: using\\nan LLM to produce realistic, relevant responses to web requests. However, Galah\\nhas a drawback. It depends on external LLMs via online APIs, which simplifies\\nthings but introduces a significant issue: latency. Most web servers should\\nrespond in under 100 milliseconds, depending on your network connection. Online\\nLLMs like ChatGPT and Gemini are large, and their response times can be slow,\\nparticularly when using inexpensive or free APIs. More importantly, these times\\ncan vary significantly. Neither of these factors is ideal when trying to imitate\\na real web server.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"what-makes-pandoras-box-different\",\n      children: \"What Makes Pandora's Box Different\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"My team thought, given how good modern LLM tech is and how fast computers are,\\nwhy not create a specialised purpose-built one? Which is exactly what we (by\\nwhich I mean Brandon, our machine learning major) did. As a base model, we chose\\na distilled low-parameter version of GPT2,\\n\", _jsx(_components.a, {\n        href: \"https://huggingface.co/distilbert/distilgpt2\",\n        children: \"distilbert/distilgpt2\"\n      }), \", mostly\\nbecause it is relatively fast to train, and very fast to run (with GPU\\nacceleration).\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"One of the largest challenges of training a model is finding relevant existing\\ndata and collecting our own. Ideally, you want a large amount of data to train\\nwith; however, given our time frame, we could not collect and prepare enough\\ndata to be useful. Instead, a large amount of the data was\\n\", _jsx(_components.a, {\n        href: \"https://github.com/Honeypotters/PandorasBox/blob/main/llm/data/syntheticifier.py\",\n        children: \"synthesised\"\n      }), \";\\nthis approach gave us lots of data in the exact format needed for training.\"]\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [\"The final model we used can be found on\\n\", _jsx(_components.a, {\n        href: \"https://huggingface.co/bangu7/honeypot-http-response\",\n        children: \"Huggingface\"\n      }), \". It was\\ntrained in about 15 minutes using 20,000 examples and can produce a result in\\nunder a second with an RTX 5070 Ti.\"]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"putting-it-together\",\n      children: \"Putting it Together\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"While the LLM was the honeypot's primary component, we still needed software for\\nthe honeypotting operations. We chose Golang for its speed, excellent built-in\\nHTTP server support, and straightforward multithreading. Lachlan and I developed\\nthis component. It consists of an HTTP server that listens for requests, sends\\nthem to the LLM running behind a Python Flask API, receives the response, and\\nconverts and sends it back to the client. We also included extensive statistics\\ncollection to provide a good user interface.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"My biggest contribution was the dashboard and statistics collection. This is a\\nminimal Next.js website that displays the request count, uptime, average\\nresponse time, an overview of the 10 most requested items and their responses,\\nand charts categorising each request. For categorisation, I used Gemini Flash 2\\nbecause it's free and the task doesn't demand rapid responses.\"\n    }), \"\\n\", _jsxs(_components.p, {\n      children: [_jsx(_components.img, {\n        src: \"https://cdn.statically.io/gh/smp46/smp46.me/nextjs/public/assets/pandorasbox/dash1.webp\",\n        alt: \"dashboard_1\"\n      }), \"\\n\", _jsx(_components.img, {\n        src: \"https://cdn.statically.io/gh/smp46/smp46.me/nextjs/public/assets/pandorasbox/dash2.webp\",\n        alt: \"dashboard_2\"\n      })]\n    }), \"\\n\", _jsx(_components.h2, {\n      id: \"the-result\",\n      children: \"The Result\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"what-could-be-better\",\n      children: \"What Could Be Better\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"Our model's biggest limitation was the synthesised data. Ideally, we would have\\npreferred to use much more real and unique data. This would have led to a far\\nmore varied and creative model. Handling HTTPS would have also been beneficial,\\nthough I'm still unsure how to manage certificates for that.\"\n    }), \"\\n\", _jsx(_components.h3, {\n      id: \"something-functional\",\n      children: \"Something Functional\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"To our surprise, we successfully built what we set out to achieve: a working\\nAI-powered honeypot. Sending a request to the server yields a unique response\\neach time, as intended. For example, if you visit the server IP in a browser,\\nyou'll see one of several variations of different webpages. None of these pages\\nare actually stored on the honeypot; they are all generated on the fly by our\\nmodel.\"\n    }), \"\\n\", _jsx(_components.p, {\n      children: \"If you're interested in giving Pandora's Box a try, you can view the GitHub\\nthrough the link on this page. There you will also find our DevPost submission\\nstory and video.\"\n    })]\n  });\n}\nfunction MDXContent(props = {}) {\n  const {wrapper: MDXLayout} = {\n    ..._provideComponents(),\n    ...props.components\n  };\n  return MDXLayout ? _jsx(MDXLayout, {\n    ...props,\n    children: _jsx(_createMdxContent, {\n      ...props\n    })\n  }) : _createMdxContent(props);\n}\nreturn {\n  default: MDXContent\n};\n","frontmatter":{},"scope":{"title":"Pandora's Box","subtitle":"Developing an LLM-Powered Web Honeypot in 96 Hours","type":"personal","description":"Pandora's Box is an AI powered web honey-pot that utilises a fine-tuned version of distilgpt2. Through the use of an LLM, relevant, specific and personalised responses can be made to every incoming request. The project was built with Python, Golang and Typescript.\nüèÜ 5th Place Winner at LaunchHacks IV Hackathon üèÜ","keywords":"Pandoras Box, CyberSec, Hackathon, Honeypot, LLM, AI, Machine Learning, Golang, Python, Typescript, Next.js","github":"https://github.com/Honeypotters/PandorasBox","featured":true,"heroImage":"https://cdn.statically.io/gh/smp46/smp46.me/nextjs/public/assets/pandorasbox/logo.webp","date":"2025-07-15","created":"2025-07-15","updated":"2025-07-15"}}},"__N_SSG":true}